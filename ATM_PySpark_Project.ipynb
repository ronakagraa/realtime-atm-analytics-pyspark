{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAL2FjXbPacjRFv1YS1/do"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ATM Big Data Project using PySpark (RDD + DataFrame + SQL)\n",
        "\n",
        "This notebook demonstrates a complete Big Data pipeline using:\n",
        "\n",
        "- PySpark RDD API  \n",
        "- DataFrame transformations  \n",
        "- Spark SQL  \n",
        "- Fraud detection  \n",
        "- Temperature alerts  \n",
        "- Cash summary  \n",
        "- CSV output (GitHub-friendly)  \n",
        "\n",
        "Dataset size: 50,000 ATM transactions.\n"
      ],
      "metadata": {
        "id": "lyko3leR_QpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW-Zky134yHr",
        "outputId": "823d6664-4493-4216-ff16-22c7cf282aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing PySpark\n",
        "\n",
        "We set up Java 11 and Spark 3.4.2, then create a SparkSession.\n"
      ],
      "metadata": {
        "id": "plMLnJdyAE1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ATM_PySpark_Project\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "mwfLRYtq5D3T",
        "outputId": "e22a021b-7b86-41b8-cb86-bbef7288f4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e018c4ef3b0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ca21826d7244:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v4.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>ATM_PySpark_Project</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Synthetic ATM Dataset\n",
        "\n",
        "We generate 50,000 ATM transaction logs with:\n",
        "- temperature\n",
        "- number of ₹500 notes\n",
        "- number of ₹200 notes\n",
        "- transaction amount\n",
        "- timestamp\n"
      ],
      "metadata": {
        "id": "XN6uLTfNAYHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv, random, time, datetime\n",
        "\n",
        "OUTPUT = \"atm_data.csv\"\n",
        "NUM_ROWS = 20000  # reduce if your runtime is slow\n",
        "\n",
        "with open(OUTPUT, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"atm_id\",\"temp\",\"cash_500\",\"cash_200\",\"transaction_amount\",\"ts\"])\n",
        "\n",
        "    atm_ids = [f\"ATM{str(i).zfill(3)}\" for i in range(1, 21)]\n",
        "    start_time = int(time.time()) - NUM_ROWS\n",
        "\n",
        "    for i in range(NUM_ROWS):\n",
        "        atm = random.choice(atm_ids)\n",
        "        temp = random.randint(20, 80)\n",
        "        c500 = random.randint(0, 300)\n",
        "        c200 = random.randint(0, 400)\n",
        "        amount = random.randint(100, 30000)\n",
        "        ts = datetime.datetime.fromtimestamp(start_time + i).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        writer.writerow([atm, temp, c500, c200, amount, ts])\n",
        "\n",
        "print(\"Generated:\", OUTPUT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20-ejiBc5Wcm",
        "outputId": "a39066aa-62ee-4976-8b30-d9a2d1acb58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: atm_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data into PySpark DataFrame\n",
        "We load the CSV file and infer schema automatically.\n"
      ],
      "metadata": {
        "id": "JoADQDwsAe_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"atm_data.csv\", header=True, inferSchema=True)\n",
        "df.show(5)\n",
        "print(\"Total rows:\", df.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ6eET2-5b4E",
        "outputId": "eaf7fcd1-14e6-4964-d9fb-dd58bba7b854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+--------+--------+------------------+-------------------+\n",
            "|atm_id|temp|cash_500|cash_200|transaction_amount|                 ts|\n",
            "+------+----+--------+--------+------------------+-------------------+\n",
            "|ATM008|  67|      67|     167|             26872|2025-12-10 10:41:38|\n",
            "|ATM016|  45|      25|     166|             12748|2025-12-10 10:41:39|\n",
            "|ATM015|  48|     142|      84|              8473|2025-12-10 10:41:40|\n",
            "|ATM003|  28|     134|     261|              8975|2025-12-10 10:41:41|\n",
            "|ATM015|  50|     219|     328|             26019|2025-12-10 10:41:42|\n",
            "+------+----+--------+--------+------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "Total rows: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RDD Example: High Temperature Alerts\n",
        "Count all ATM logs where temperature > 50°C.\n"
      ],
      "metadata": {
        "id": "6GdE7H1EAnlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = df.rdd\n",
        "high_temp = rdd.filter(lambda row: row[\"temp\"] > 50).count()\n",
        "print(\"High temperature alerts =\", high_temp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5dVrNt55n7l",
        "outputId": "7e4487f2-d849-48b7-864a-552be6fe2636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "High temperature alerts = 9907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add a new column 'total_cash'\n",
        "total_cash = (cash_500 * 500) + (cash_200 * 200)\n"
      ],
      "metadata": {
        "id": "-VCNxNIaAsq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df2 = df.withColumn(\"total_cash\", col(\"cash_500\")*500 + col(\"cash_200\")*200)\n",
        "df2.show(5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KhciCk15ssU",
        "outputId": "24de3a60-5ffd-4ab6-f115-6fd88c63355f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+--------+--------+------------------+-------------------+----------+\n",
            "|atm_id|temp|cash_500|cash_200|transaction_amount|                 ts|total_cash|\n",
            "+------+----+--------+--------+------------------+-------------------+----------+\n",
            "|ATM008|  67|      67|     167|             26872|2025-12-10 10:41:38|     66900|\n",
            "|ATM016|  45|      25|     166|             12748|2025-12-10 10:41:39|     45700|\n",
            "|ATM015|  48|     142|      84|              8473|2025-12-10 10:41:40|     87800|\n",
            "|ATM003|  28|     134|     261|              8975|2025-12-10 10:41:41|    119200|\n",
            "|ATM015|  50|     219|     328|             26019|2025-12-10 10:41:42|    175100|\n",
            "+------+----+--------+--------+------------------+-------------------+----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fraud Detection using Spark SQL\n",
        "Fraud = transaction_amount > 10,000\n"
      ],
      "metadata": {
        "id": "X_Jr_ZCzA-JN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.createOrReplaceTempView(\"atm\")\n",
        "\n",
        "fraud_df = spark.sql(\"\"\"\n",
        "SELECT atm_id, temp, cash_500, cash_200, transaction_amount, ts\n",
        "FROM atm\n",
        "WHERE transaction_amount > 10000\n",
        "\"\"\")\n",
        "\n",
        "fraud_df.show(10)\n",
        "print(\"Fraud count:\", fraud_df.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNNdxaD750X3",
        "outputId": "d4fa8f50-9d22-4f2d-88af-f92584b24a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+--------+--------+------------------+-------------------+\n",
            "|atm_id|temp|cash_500|cash_200|transaction_amount|                 ts|\n",
            "+------+----+--------+--------+------------------+-------------------+\n",
            "|ATM008|  67|      67|     167|             26872|2025-12-10 10:41:38|\n",
            "|ATM016|  45|      25|     166|             12748|2025-12-10 10:41:39|\n",
            "|ATM015|  50|     219|     328|             26019|2025-12-10 10:41:42|\n",
            "|ATM016|  61|      29|     293|             26244|2025-12-10 10:41:43|\n",
            "|ATM006|  64|     229|     234|             22421|2025-12-10 10:41:44|\n",
            "|ATM020|  27|      39|     230|             17159|2025-12-10 10:41:45|\n",
            "|ATM020|  32|     265|     344|             18523|2025-12-10 10:41:46|\n",
            "|ATM019|  66|     112|      16|             10898|2025-12-10 10:41:47|\n",
            "|ATM013|  57|      11|     109|             21829|2025-12-10 10:41:48|\n",
            "|ATM017|  28|      25|      12|             29089|2025-12-10 10:41:49|\n",
            "+------+----+--------+--------+------------------+-------------------+\n",
            "only showing top 10 rows\n",
            "Fraud count: 13340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temperature Alerts (temp > 50°C)\n"
      ],
      "metadata": {
        "id": "ncrbdO0oBDtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = df2.filter(col(\"temp\") > 50)\n",
        "temp_df.show(5)\n",
        "print(\"Temperature alert rows:\", temp_df.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdn1Dh9LK818",
        "outputId": "8864facb-714b-495f-d089-72efa10508d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+--------+--------+------------------+-------------------+----------+\n",
            "|atm_id|temp|cash_500|cash_200|transaction_amount|                 ts|total_cash|\n",
            "+------+----+--------+--------+------------------+-------------------+----------+\n",
            "|ATM008|  67|      67|     167|             26872|2025-12-10 10:41:38|     66900|\n",
            "|ATM016|  61|      29|     293|             26244|2025-12-10 10:41:43|     73100|\n",
            "|ATM006|  64|     229|     234|             22421|2025-12-10 10:41:44|    161300|\n",
            "|ATM019|  66|     112|      16|             10898|2025-12-10 10:41:47|     59200|\n",
            "|ATM013|  57|      11|     109|             21829|2025-12-10 10:41:48|     27300|\n",
            "+------+----+--------+--------+------------------+-------------------+----------+\n",
            "only showing top 5 rows\n",
            "Temperature alert rows: 9907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate Cash Summary per ATM\n",
        "Calculates average total_cash for each ATM ID.\n"
      ],
      "metadata": {
        "id": "r9hgybeKLGFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "cash_summary = df2.groupBy(\"atm_id\").agg(avg(\"total_cash\").alias(\"avg_total_cash\"))\n",
        "cash_summary.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCL1v5juLHIP",
        "outputId": "0ac4c876-39d0-4540-f40a-186dc03eab2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+\n",
            "|atm_id|    avg_total_cash|\n",
            "+------+------------------+\n",
            "|ATM009|115957.54716981133|\n",
            "|ATM019|116029.37198067633|\n",
            "|ATM018|114216.96606786427|\n",
            "|ATM002|114679.09715407262|\n",
            "|ATM015|117035.53553553554|\n",
            "|ATM005|115231.67701863353|\n",
            "|ATM008|116716.66666666667|\n",
            "|ATM017| 115828.1473899693|\n",
            "|ATM001|114561.79540709812|\n",
            "|ATM007|    113175.5859375|\n",
            "+------+------------------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Outputs as CSV\n",
        "\n"
      ],
      "metadata": {
        "id": "mjWzvSVQBQre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_df.coalesce(1).write.mode(\"overwrite\").csv(\"fraud_output\", header=True)\n",
        "temp_df.coalesce(1).write.mode(\"overwrite\").csv(\"temp_output\", header=True)\n",
        "cash_summary.coalesce(1).write.mode(\"overwrite\").csv(\"cash_summary_output\", header=True)\n"
      ],
      "metadata": {
        "id": "UdHI0D2q5_q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Generated CSV Files.\n"
      ],
      "metadata": {
        "id": "ya-SbmGgBUp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"atm_data.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ijJF3F1r6F3r",
        "outputId": "2af4fc72-92d7-42ef-fed2-fa36f6d5c948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_67567f1e-93b9-4539-b3c1-33b3d6c7494b\", \"atm_data.csv\", 880084)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}